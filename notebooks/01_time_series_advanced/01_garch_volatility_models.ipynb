{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941d860e",
   "metadata": {},
   "source": [
    "# GARCH & EGARCH Volatility Models: A Deep Dive for Quant Traders\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "\n",
    "1. **Mathematical foundations** of ARCH, GARCH, and EGARCH models\n",
    "2. **Geometric intuition** behind volatility clustering\n",
    "3. **Step-by-step derivations** of key formulas\n",
    "4. **Numerical examples** with hand calculations\n",
    "5. **Trading applications** integrating RSI, divergences, W/M patterns\n",
    "6. **Python implementation** from scratch and with libraries\n",
    "7. **Risk management** strategies using volatility forecasts\n",
    "8. **Common mistakes** and how to avoid them\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic time series concepts (AR, MA, ARMA)\n",
    "- Maximum likelihood estimation\n",
    "- Basic options pricing knowledge\n",
    "- Python proficiency\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Theory & Intuition** - Why volatility models matter\n",
    "2. **ARCH Models** - The foundation\n",
    "3. **GARCH Models** - Adding persistence\n",
    "4. **EGARCH Models** - Asymmetric effects\n",
    "5. **Trading Applications** - Real-world strategies\n",
    "6. **Integration with Technical Analysis** - RSI, divergences, patterns\n",
    "7. **Mini Project** - Complete volatility trading system\n",
    "8. **Exercises** - Test your understanding\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Cristian Mendoza  \n",
    "**Level**: Advanced  \n",
    "**Estimated Time**: 4-6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "\n",
    "# GARCH models\n",
    "from arch import arch_model\n",
    "from arch.univariate import GARCH, EGARCH, ConstantMean, ZeroMean\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Technical analysis\n",
    "try:\n",
    "    import ta\n",
    "    from ta.momentum import RSIIndicator\n",
    "    from ta.trend import MACD\n",
    "    from ta.volume import OnBalanceVolumeIndicator\n",
    "except ImportError:\n",
    "    print(\"Installing ta library...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'ta'])\n",
    "    import ta\n",
    "    from ta.momentum import RSIIndicator\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86719e3c",
   "metadata": {},
   "source": [
    "# Part 2: Theory & Intuition - Why Volatility Models Matter\n",
    "\n",
    "## The Big Picture\n",
    "\n",
    "**Key Question**: Why can't we just use standard deviation?\n",
    "\n",
    "**Answer**: Financial returns exhibit **volatility clustering**:\n",
    "- Calm periods follow calm periods\n",
    "- Volatile periods follow volatile periods\n",
    "- \"Large changes tend to be followed by large changes, of either sign\" - Benoit Mandelbrot\n",
    "\n",
    "## Geometric Visualization\n",
    "\n",
    "Think of volatility as the \"size of waves\" in the ocean:\n",
    "```\n",
    "Low Volatility Period:       High Volatility Period:\n",
    "~~~~~~                       /\\/\\/\\/\\\n",
    "      ~~~~~~                 \\/\\/\\/\\/\n",
    "            ~~~~~~           /\\/\\/\\/\\\n",
    "\n",
    "Calm, predictable           Wild, unpredictable\n",
    "```\n",
    "\n",
    "## Mathematical Motivation\n",
    "\n",
    "**Problem with constant volatility**:\n",
    "\n",
    "Traditional assumption: $r_t \\sim N(\\mu, \\sigma^2)$ where $\\sigma$ is constant.\n",
    "\n",
    "**Reality**: $\\sigma_t$ changes over time!\n",
    "\n",
    "**Solution**: Model $\\sigma_t^2$ as a time-varying function of past information.\n",
    "\n",
    "## ðŸ’¡ Core Insight\n",
    "\n",
    "GARCH models say:\n",
    "> \"Tomorrow's volatility depends on:\n",
    "> 1. Today's surprise (squared return)\n",
    "> 2. Today's volatility\n",
    "> 3. A long-run average volatility\"\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2$$\n",
    "\n",
    "Where:\n",
    "- $\\omega$ = baseline volatility\n",
    "- $\\alpha$ = news coefficient (how much new shocks matter)\n",
    "- $\\beta$ = persistence coefficient (how much history matters)\n",
    "\n",
    "## Trading Implications\n",
    "\n",
    "1. **Option Pricing**: Use $\\sigma_t$ instead of historical $\\sigma$\n",
    "2. **Risk Management**: Adjust position sizes based on $\\sigma_t$\n",
    "3. **Mean Reversion**: High volatility eventually subsides\n",
    "4. **Regime Detection**: Identify volatility regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc510e43",
   "metadata": {},
   "source": [
    "# Part 1: Environment Setup\n",
    "\n",
    "Import all necessary libraries for volatility modeling and trading analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e96a3e",
   "metadata": {},
   "source": [
    "# Part 3: Visual Demonstration of Volatility Clustering\n",
    "\n",
    "Let's load real data and see volatility clustering in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download S&P 500 data\n",
    "ticker = 'SPY'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "print(f\"Downloading {ticker} data from {start_date} to {end_date}...\")\n",
    "data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "# Calculate returns\n",
    "data['Returns'] = data['Close'].pct_change() * 100  # In percentage\n",
    "data = data.dropna()\n",
    "\n",
    "print(f\"\\nâœ“ Data downloaded: {len(data)} trading days\")\n",
    "print(f\"Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "print(f\"\\nReturns Statistics:\")\n",
    "print(f\"  Mean: {data['Returns'].mean():.4f}%\")\n",
    "print(f\"  Std Dev: {data['Returns'].std():.4f}%\")\n",
    "print(f\"  Min: {data['Returns'].min():.4f}%\")\n",
    "print(f\"  Max: {data['Returns'].max():.4f}%\")\n",
    "print(f\"  Skewness: {data['Returns'].skew():.4f}\")\n",
    "print(f\"  Kurtosis: {data['Returns'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2171c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize volatility clustering\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
    "\n",
    "# 1. Price chart\n",
    "axes[0].plot(data.index, data['Close'], linewidth=1.5, color='steelblue')\n",
    "axes[0].set_title('S&P 500 (SPY) Price Chart', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Returns\n",
    "axes[1].plot(data.index, data['Returns'], linewidth=0.8, color='darkgreen', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Daily Returns - Notice the Clustering!', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Returns (%)')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Highlight volatility clusters\n",
    "axes[1].axvspan('2020-02-01', '2020-05-01', alpha=0.2, color='red', label='COVID-19 Volatility')\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Absolute returns (proxy for volatility)\n",
    "axes[2].plot(data.index, np.abs(data['Returns']), linewidth=0.8, color='darkred', alpha=0.7)\n",
    "axes[2].set_title('Absolute Returns (Volatility Proxy)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('|Returns| (%)')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOBSERVATION:\")\n",
    "print(\"Notice how high volatility periods cluster together (especially Mar 2020).\")\n",
    "print(\"This is what GARCH models capture: volatility is NOT constant!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53040de",
   "metadata": {},
   "source": [
    "# Part 4: ARCH Model - The Foundation\n",
    "\n",
    "## Mathematical Definition\n",
    "\n",
    "**ARCH(q)** (Autoregressive Conditional Heteroskedasticity):\n",
    "\n",
    "$$r_t = \\sigma_t \\varepsilon_t$$\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\sum_{i=1}^{q} \\alpha_i r_{t-i}^2$$\n",
    "\n",
    "Where:\n",
    "- $r_t$ = return at time $t$\n",
    "- $\\varepsilon_t \\sim N(0,1)$ = standardized innovation\n",
    "- $\\sigma_t^2$ = conditional variance (time-varying!)\n",
    "- $\\omega > 0$ = baseline variance\n",
    "- $\\alpha_i \\geq 0$ = ARCH coefficients\n",
    "\n",
    "## Key Properties\n",
    "\n",
    "1. **Conditional variance** depends on past squared returns\n",
    "2. **Unconditional variance** is constant (if stationary)\n",
    "3. **Fat tails**: ARCH generates leptokurtic distributions\n",
    "4. **Volatility clustering**: Large |returns| follow large |returns|\n",
    "\n",
    "## ARCH(1) Example - Hand Calculation\n",
    "\n",
    "Let's work through ARCH(1) step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCH(1) Manual Calculation\n",
    "print(\"=\"*60)\n",
    "print(\"ARCH(1) MODEL: ÏƒÂ²_t = Ï‰ + Î±â‚ Ã— rÂ²_{t-1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parameters\n",
    "omega = 0.01\n",
    "alpha_1 = 0.3\n",
    "\n",
    "# Initial conditions\n",
    "r_0 = 0.02  # 2% initial return\n",
    "sigma_0 = 0.02  # 2% initial volatility\n",
    "\n",
    "# Random shocks\n",
    "np.random.seed(42)\n",
    "shocks = np.array([-0.5, 1.2, 0.3, -0.8, 0.5])\n",
    "\n",
    "print(f\"\\nParameters: Ï‰ = {omega}, Î±â‚ = {alpha_1}\")\n",
    "print(f\"Initial: râ‚€ = {r_0:.4f} ({r_0*100:.2f}%), Ïƒâ‚€ = {sigma_0:.4f}\\n\")\n",
    "\n",
    "# Simulate\n",
    "volatilities = [sigma_0]\n",
    "returns = [r_0]\n",
    "\n",
    "for t, epsilon in enumerate(shocks, start=1):\n",
    "    # Step 1: Calculate variance at time t\n",
    "    r_prev = returns[-1]\n",
    "    sigma_t_squared = omega + alpha_1 * (r_prev ** 2)\n",
    "    sigma_t = np.sqrt(sigma_t_squared)\n",
    "    \n",
    "    # Step 2: Calculate return at time t\n",
    "    r_t = sigma_t * epsilon\n",
    "    \n",
    "    volatilities.append(sigma_t)\n",
    "    returns.append(r_t)\n",
    "    \n",
    "    # Display\n",
    "    print(f\"Period t={t}:\")\n",
    "    print(f\"  ÏƒÂ²_{t} = {omega} + {alpha_1} Ã— ({r_prev:.4f})Â²\")\n",
    "    print(f\"       = {omega} + {alpha_1} Ã— {r_prev**2:.6f}\")\n",
    "    print(f\"       = {sigma_t_squared:.6f}\")\n",
    "    print(f\"  Ïƒ_{t}  = âˆš{sigma_t_squared:.6f} = {sigma_t:.4f} ({sigma_t*100:.2f}%)\")\n",
    "    print(f\"  r_{t}  = {sigma_t:.4f} Ã— {epsilon:.2f} = {r_t:.4f} ({r_t*100:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY - Volatility Over Time:\")\n",
    "print(\"=\"*60)\n",
    "for t, (vol, ret) in enumerate(zip(volatilities, returns)):\n",
    "    print(f\"t={t}: Ïƒ={vol*100:6.2f}%  r={ret*100:7.2f}%\")\n",
    "\n",
    "# Find maximum volatility\n",
    "max_vol_idx = np.argmax(volatilities)\n",
    "print(f\"\\n MAXIMUM VOLATILITY at t={max_vol_idx}: {volatilities[max_vol_idx]*100:.2f}%\")\n",
    "print(f\"\\n KEY INSIGHT: Large returns increase future volatility!\")\n",
    "print(f\"   This is 'volatility clustering' captured by ARCH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14503d93",
   "metadata": {},
   "source": [
    "# Part 5: GARCH Model - Adding Persistence\n",
    "\n",
    "## Motivation\n",
    "\n",
    "**Problem with ARCH**: Need many lags (large q) to capture long-memory volatility\n",
    "\n",
    "**Solution**: GARCH adds lagged conditional variance\n",
    "\n",
    "## GARCH(p,q) Definition\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\sum_{i=1}^{q} \\alpha_i r_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2$$\n",
    "\n",
    "**Most Common: GARCH(1,1)**\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2$$\n",
    "\n",
    "Where:\n",
    "- $\\omega$ = long-run variance component\n",
    "- $\\alpha$ = news coefficient (reaction to shocks)\n",
    "- $\\beta$ = persistence coefficient (memory of past volatility)\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "GARCH(1,1) says tomorrow's volatility depends on:\n",
    "1. **Long-run average** (Ï‰)\n",
    "2. **Yesterday's surprise** (Î± Ã— rÂ²)\n",
    "3. **Yesterday's volatility** (Î² Ã— ÏƒÂ²)\n",
    "\n",
    "## Persistence Measure\n",
    "\n",
    "$$\\text{Persistence} = \\alpha + \\beta$$\n",
    "\n",
    "- Close to 1 â†’ Very persistent (slow decay)\n",
    "- Far from 1 â†’ Quick mean reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARCH(1,1) Manual Calculation\n",
    "print(\"=\"*70)\n",
    "print(\"GARCH(1,1) MODEL: ÏƒÂ²_t = Ï‰ + Î± Ã— rÂ²_{t-1} + Î² Ã— ÏƒÂ²_{t-1}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Typical market parameters\n",
    "omega = 0.00001\n",
    "alpha = 0.08\n",
    "beta = 0.90\n",
    "\n",
    "print(f\"\\nParameters (typical for equity markets):\")\n",
    "print(f\"  Ï‰ = {omega:.6f}\")\n",
    "print(f\"  Î± = {alpha:.6f}\")\n",
    "print(f\"  Î² = {beta:.6f}\")\n",
    "print(f\"  Persistence (Î± + Î²) = {alpha + beta:.6f}\")\n",
    "print(f\"  {'Very persistent!' if alpha + beta > 0.95 else 'Moderate persistence'}\")\n",
    "\n",
    "# Unconditional variance\n",
    "var_uncond = omega / (1 - alpha - beta)\n",
    "sigma_uncond = np.sqrt(var_uncond)\n",
    "print(f\"\\nUnconditional variance: {var_uncond:.6f}\")\n",
    "print(f\"Unconditional volatility: {sigma_uncond:.4f} ({sigma_uncond*100:.2f}%)\")\n",
    "\n",
    "# Initial conditions\n",
    "sigma_0_sq = 0.0004  # Initial variance\n",
    "r_0 = 0.03  # 3% return\n",
    "\n",
    "# Shocks\n",
    "shocks = np.array([1.5, 0.1, 0.1, -2.0, 0.2])\n",
    "\n",
    "print(f\"\\nInitial: râ‚€ = {r_0:.4f}, Ïƒâ‚€Â² = {sigma_0_sq:.6f}\\n\")\n",
    "\n",
    "# Simulate\n",
    "sigma_sq = [sigma_0_sq]\n",
    "returns = [r_0]\n",
    "\n",
    "for t, eps in enumerate(shocks, start=1):\n",
    "    r_prev = returns[-1]\n",
    "    sigma_prev_sq = sigma_sq[-1]\n",
    "    \n",
    "    # GARCH equation\n",
    "    sigma_t_sq = omega + alpha * r_prev**2 + beta * sigma_prev_sq\n",
    "    sigma_t = np.sqrt(sigma_t_sq)\n",
    "    r_t = sigma_t * eps\n",
    "    \n",
    "    sigma_sq.append(sigma_t_sq)\n",
    "    returns.append(r_t)\n",
    "    \n",
    "    print(f\"Period t={t}:\")\n",
    "    print(f\"  ÏƒÂ²_{t} = {omega:.6f} + {alpha:.2f}Ã—({r_prev:.4f})Â² + {beta:.2f}Ã—{sigma_prev_sq:.6f}\")\n",
    "    print(f\"       = {omega:.6f} + {alpha * r_prev**2:.6f} + {beta * sigma_prev_sq:.6f}\")\n",
    "    print(f\"       = {sigma_t_sq:.6f}\")\n",
    "    print(f\"  Ïƒ_{t}  = {sigma_t:.4f} ({sigma_t*100:.2f}%)\")\n",
    "    print(f\"  r_{t}  = {sigma_t:.4f} Ã— {eps:.2f} = {r_t:.4f} ({r_t*100:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# Analysis\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARISON: How volatility evolves\")\n",
    "print(\"=\"*70)\n",
    "for t in range(len(sigma_sq)):\n",
    "    sigma_pct = np.sqrt(sigma_sq[t]) * 100\n",
    "    if t == 0:\n",
    "        print(f\"t={t}: Ïƒ={sigma_pct:6.2f}%  (initial)\")\n",
    "    else:\n",
    "        print(f\"t={t}: Ïƒ={sigma_pct:6.2f}%  r={returns[t]*100:7.2f}%  shock={shocks[t-1]:5.2f}\")\n",
    "\n",
    "print(f\"\\nKEY OBSERVATION:\")\n",
    "print(f\"After large shock at t=1 (Îµ=1.5), volatility increased to {np.sqrt(sigma_sq[1])*100:.2f}%\")\n",
    "print(f\"But it PERSISTS due to Î² term, decaying slowly back to long-run average\")\n",
    "print(f\"This is why GARCH is better than ARCH for capturing persistent volatility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c24151",
   "metadata": {},
   "source": [
    "# Part 6: Estimating GARCH with Real Data\n",
    "\n",
    "## Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "The log-likelihood function for GARCH(1,1):\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = \\sum_{t=1}^{T} \\left[-\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma_t^2) - \\frac{r_t^2}{2\\sigma_t^2}\\right]$$\n",
    "\n",
    "where $\\theta = (\\omega, \\alpha, \\beta)$\n",
    "\n",
    "We maximize this to find optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce479f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate GARCH(1,1) on S&P 500 returns\n",
    "print(\"Estimating GARCH(1,1) model on S&P 500 returns...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use returns from earlier\n",
    "returns_series = data['Returns'].dropna()\n",
    "\n",
    "# Fit GARCH(1,1) model\n",
    "model = arch_model(returns_series, vol='Garch', p=1, q=1, dist='normal')\n",
    "result = model.fit(disp='off')\n",
    "\n",
    "# Display results\n",
    "print(result.summary())\n",
    "\n",
    "# Extract parameters\n",
    "params = result.params\n",
    "omega_est = params['omega']\n",
    "alpha_est = params['alpha[1]']\n",
    "beta_est = params['beta[1]']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ESTIMATED PARAMETERS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Ï‰ (omega)     = {omega_est:.8f}\")\n",
    "print(f\"Î± (alpha)     = {alpha_est:.6f}\")\n",
    "print(f\"Î² (beta)      = {beta_est:.6f}\")\n",
    "print(f\"Persistence   = {alpha_est + beta_est:.6f}\")\n",
    "\n",
    "# Unconditional volatility\n",
    "var_uncond_est = omega_est / (1 - alpha_est - beta_est)\n",
    "sigma_uncond_est = np.sqrt(var_uncond_est)\n",
    "\n",
    "print(f\"\\nUnconditional variance: {var_uncond_est:.6f}\")\n",
    "print(f\"Unconditional vol (daily): {sigma_uncond_est:.4f} ({sigma_uncond_est*100:.2f}%)\")\n",
    "print(f\"Annualized volatility: {sigma_uncond_est * np.sqrt(252):.4f} ({sigma_uncond_est * np.sqrt(252) * 100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"1. High persistence ({alpha_est + beta_est:.4f}) means volatility is very sticky\")\n",
    "print(f\"2. Î² > Î± means past volatility matters MORE than recent shocks\")\n",
    "print(f\"3. Long-run daily vol ~{sigma_uncond_est*100:.2f}% or ~{sigma_uncond_est * np.sqrt(252) * 100:.1f}% annualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8aa05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and plot conditional volatility\n",
    "conditional_vol = result.conditional_volatility\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Returns with conditional volatility\n",
    "axes[0].plot(data.index, data['Returns'], alpha=0.5, linewidth=0.8, label='Returns')\n",
    "axes[0].plot(data.index, conditional_vol, color='red', linewidth=2, label='Conditional Volatility (Ïƒ_t)')\n",
    "axes[0].plot(data.index, -conditional_vol, color='red', linewidth=2)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0].set_title('S&P 500 Returns with GARCH(1,1) Conditional Volatility', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Returns / Volatility (%)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Just volatility\n",
    "axes[1].plot(data.index, conditional_vol, color='darkred', linewidth=1.5)\n",
    "axes[1].axhline(y=sigma_uncond_est, color='blue', linestyle='--', linewidth=2, \n",
    "                label=f'Long-run vol = {sigma_uncond_est*100:.2f}%')\n",
    "axes[1].set_title('GARCH(1,1) Conditional Volatility Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility (%)')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Highlight COVID-19 period\n",
    "axes[1].axvspan('2020-02-01', '2020-05-01', alpha=0.2, color='red', label='COVID-19')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOBSERVATION:\")\n",
    "print(\"Notice how volatility spikes during market stress (COVID-19) and\")\n",
    "print(\"gradually reverts to the long-run average. This is GARCH in action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb18e81",
   "metadata": {},
   "source": [
    "# Part 7: EGARCH Model - Capturing Asymmetry\n",
    "\n",
    "## The Leverage Effect\n",
    "\n",
    "**Observation**: Negative returns increase volatility MORE than positive returns of equal magnitude.\n",
    "\n",
    "**Why?**\n",
    "- Bad news creates panic\n",
    "- Falling prices increase leverage ratios\n",
    "- Margin calls amplify downward pressure\n",
    "\n",
    "**Problem with GARCH**: It's symmetric! A +5% and -5% return have the same impact.\n",
    "\n",
    "## EGARCH(1,1) Definition\n",
    "\n",
    "$$\\log(\\sigma_t^2) = \\omega + \\alpha \\left|z_{t-1}\\right| + \\gamma z_{t-1} + \\beta \\log(\\sigma_{t-1}^2)$$\n",
    "\n",
    "where $z_t = \\frac{\\varepsilon_t}{\\sigma_t} = \\frac{r_t}{\\sigma_t}$ is the standardized residual.\n",
    "\n",
    "**Key Parameter: Î³ (gamma)**\n",
    "- Î³ < 0: Negative shocks increase volatility MORE (typical for stocks)\n",
    "- Î³ = 0: Symmetric (like GARCH)\n",
    "- Î³ > 0: Positive shocks increase volatility MORE (rare)\n",
    "\n",
    "**Advantages of EGARCH**:\n",
    "1. Captures leverage effect (asymmetry)\n",
    "2. No need for parameter constraints (log ensures ÏƒÂ² > 0)\n",
    "3. Better for stock markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75197318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate EGARCH(1,1)\n",
    "print(\"Estimating EGARCH(1,1) model on S&P 500 returns...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_egarch = arch_model(returns_series, vol='EGARCH', p=1, q=1, dist='normal')\n",
    "result_egarch = model_egarch.fit(disp='off')\n",
    "\n",
    "print(result_egarch.summary())\n",
    "\n",
    "# Extract parameters\n",
    "params_e = result_egarch.params\n",
    "omega_e = params_e['omega']\n",
    "alpha_e = params_e['alpha[1]']\n",
    "gamma_e = params_e['gamma[1]']\n",
    "beta_e = params_e['beta[1]']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EGARCH PARAMETERS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Ï‰ (omega) = {omega_e:.6f}\")\n",
    "print(f\"Î± (alpha) = {alpha_e:.6f}\")\n",
    "print(f\"Î³ (gamma) = {gamma_e:.6f}  <- KEY: Asymmetry parameter\")\n",
    "print(f\"Î² (beta)  = {beta_e:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION OF Î³:\")\n",
    "print(\"=\"*70)\n",
    "if gamma_e < 0:\n",
    "    print(f\"Î³ = {gamma_e:.6f} < 0\")\n",
    "    print(\"NEGATIVE shocks (market drops) increase volatility MORE than positive shocks\")\n",
    "    print(\"This confirms the LEVERAGE EFFECT in stock markets\")\n",
    "elif gamma_e > 0:\n",
    "    print(f\"Î³ = {gamma_e:.6f} > 0\")\n",
    "    print(\"POSITIVE shocks increase volatility more (unusual for stocks)\")\n",
    "else:\n",
    "    print(f\"Î³ â‰ˆ 0: Symmetric response (like GARCH)\")\n",
    "\n",
    "# Compare GARCH vs EGARCH\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GARCH vs EGARCH COMPARISON:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<15} {'Ï‰':<12} {'Î±':<10} {'Î²':<10} {'Î³':<10} {'Log-Lik':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'GARCH(1,1)':<15} {omega_est:<12.8f} {alpha_est:<10.6f} {beta_est:<10.6f} {'N/A':<10} {result.loglikelihood:<12.2f}\")\n",
    "print(f\"{'EGARCH(1,1)':<15} {omega_e:<12.8f} {alpha_e:<10.6f} {beta_e:<10.6f} {gamma_e:<10.6f} {result_egarch.loglikelihood:<12.2f}\")\n",
    "\n",
    "if result_egarch.loglikelihood > result.loglikelihood:\n",
    "    print(f\"\\nEGARCH has HIGHER log-likelihood â†’ Better fit for this data\")\n",
    "else:\n",
    "    print(f\"\\nGARCH has HIGHER log-likelihood â†’ Better fit for this data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42045f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate asymmetry with simulation\n",
    "print(\"=\"*70)\n",
    "print(\"DEMONSTRATING ASYMMETRY: +5% vs -5% shock\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initial conditions\n",
    "sigma_init = 0.02  # 2% daily vol\n",
    "\n",
    "def simulate_egarch_shock(shock, sigma_init, omega, alpha, gamma, beta, periods=10):\n",
    "    \"\"\"Simulate EGARCH response to a shock\"\"\"\n",
    "    log_sigma2 = np.zeros(periods + 1)\n",
    "    log_sigma2[0] = np.log(sigma_init**2)\n",
    "    \n",
    "    for t in range(1, periods + 1):\n",
    "        if t == 1:\n",
    "            z = shock / sigma_init\n",
    "        else:\n",
    "            z = 0  # No more shocks\n",
    "        \n",
    "        log_sigma2[t] = omega + alpha * abs(z) + gamma * z + beta * log_sigma2[t-1]\n",
    "    \n",
    "    return np.exp(log_sigma2 / 2)\n",
    "\n",
    "# Positive shock\n",
    "shock_pos = 0.05  # +5%\n",
    "sigma_pos = simulate_egarch_shock(shock_pos, sigma_init, omega_e, alpha_e, gamma_e, beta_e)\n",
    "\n",
    "# Negative shock\n",
    "shock_neg = -0.05  # -5%\n",
    "sigma_neg = simulate_egarch_shock(shock_neg, sigma_init, omega_e, alpha_e, gamma_e, beta_e)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nInitial volatility: {sigma_init*100:.2f}%\\n\")\n",
    "print(f\"After +5% shock:\")\n",
    "print(f\"  Day 1: Ïƒ = {sigma_pos[1]*100:.2f}% (increase of {(sigma_pos[1]/sigma_init - 1)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAfter -5% shock:\")\n",
    "print(f\"  Day 1: Ïƒ = {sigma_neg[1]*100:.2f}% (increase of {(sigma_neg[1]/sigma_init - 1)*100:.1f}%)\")\n",
    "\n",
    "diff = sigma_neg[1] - sigma_pos[1]\n",
    "print(f\"\\nDIFFERENCE: {diff*100:.3f}%\")\n",
    "print(f\"The NEGATIVE shock increased volatility by {diff/sigma_pos[1]*100:.1f}% MORE\")\n",
    "print(f\"This is the leverage effect captured by Î³ = {gamma_e:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "periods = range(len(sigma_pos))\n",
    "ax.plot(periods, sigma_pos * 100, 'g-', marker='o', linewidth=2, markersize=6, label='+5% shock')\n",
    "ax.plot(periods, sigma_neg * 100, 'r-', marker='o', linewidth=2, markersize=6, label='-5% shock')\n",
    "ax.axhline(y=sigma_init*100, color='blue', linestyle='--', alpha=0.5, label='Initial vol')\n",
    "ax.set_xlabel('Days after shock')\n",
    "ax.set_ylabel('Volatility (%)')\n",
    "ax.set_title('EGARCH Asymmetric Response: Negative Shocks Hit Harder', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKEY TAKEAWAY:\")\n",
    "print(\"EGARCH captures the asymmetry in real markets where crashes increase\")\n",
    "print(\"volatility more than rallies. This is crucial for risk management!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6df6f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Volatility Forecasting\n",
    "\n",
    "Now we generate multi-step ahead volatility forecasts, which are critical for:\n",
    "\n",
    "- **Position sizing**: Scale positions inversely with forecasted volatility\n",
    "- **Risk budgeting**: Allocate risk across assets based on vol forecasts\n",
    "- **Option pricing**: Implied vol comparison with model forecasts\n",
    "- **Dynamic hedging**: Adjust hedge ratios as volatility changes\n",
    "\n",
    "GARCH models provide analytical forecasts for conditional variance:\n",
    "\n",
    "**GARCH(1,1) h-step ahead forecast:**\n",
    "\n",
    "$$\\hat{\\sigma}^2_{t+h|t} = \\sigma^2_{LR} + (\\alpha + \\beta)^h \\left( \\hat{\\sigma}^2_{t+1|t} - \\sigma^2_{LR} \\right)$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma^2_{LR} = \\frac{\\omega}{1 - \\alpha - \\beta}$ is the long-run variance\n",
    "- $(\\alpha + \\beta)^h$ controls mean reversion speed\n",
    "- As $h \\to \\infty$, forecast converges to $\\sigma^2_{LR}$\n",
    "\n",
    "**Key properties:**\n",
    "- Forecasts decay exponentially to long-run mean\n",
    "- High persistence ($\\alpha + \\beta \\approx 1$) means slow decay\n",
    "- Recent shocks have long-lasting impact on forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b314fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-step ahead forecasts\n",
    "horizon = 20  # Forecast 20 days ahead\n",
    "\n",
    "# GARCH forecasts\n",
    "forecasts_garch = result_garch.forecast(horizon=horizon, start=0)\n",
    "variance_forecast_garch = forecasts_garch.variance.iloc[-1]  # Last available forecast\n",
    "\n",
    "# EGARCH forecasts\n",
    "forecasts_egarch = result_egarch.forecast(horizon=horizon, start=0)\n",
    "variance_forecast_egarch = forecasts_egarch.variance.iloc[-1]\n",
    "\n",
    "# Convert to volatility (standard deviation)\n",
    "vol_forecast_garch = np.sqrt(variance_forecast_garch)\n",
    "vol_forecast_egarch = np.sqrt(variance_forecast_egarch)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"VOLATILITY FORECASTS (Next {horizon} Days)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nLast observation date: {returns_series.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Last realized volatility: {conditional_vol_garch.iloc[-1]*100:.2f}%\\n\")\n",
    "\n",
    "print(\"GARCH(1,1) Forecasts:\")\n",
    "print(\"-\" * 40)\n",
    "for h in [1, 5, 10, 20]:\n",
    "    print(f\"  t+{h:2d}: {vol_forecast_garch.iloc[h-1]*100:5.2f}%\")\n",
    "\n",
    "print(\"\\nEGARCH(1,1) Forecasts:\")\n",
    "print(\"-\" * 40)\n",
    "for h in [1, 5, 10, 20]:\n",
    "    print(f\"  t+{h:2d}: {vol_forecast_egarch.iloc[h-1]*100:5.2f}%\")\n",
    "\n",
    "# Calculate long-run volatility\n",
    "lr_vol_garch = np.sqrt(omega_g / (1 - alpha_g - beta_g))\n",
    "print(f\"\\nLong-run volatility (GARCH): {lr_vol_garch*100:.2f}%\")\n",
    "\n",
    "# Show mean reversion\n",
    "persistence = alpha_g + beta_g\n",
    "print(f\"\\nPersistence (Î± + Î²): {persistence:.4f}\")\n",
    "print(f\"Half-life of shocks: {np.log(0.5) / np.log(persistence):.1f} days\")\n",
    "print(\"(Time for a shock to decay to 50% of its initial impact)\")\n",
    "\n",
    "# Visualize forecasts\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Forecast paths\n",
    "ax1.plot(range(1, horizon+1), vol_forecast_garch * 100, \n",
    "         'b-', marker='o', linewidth=2, markersize=5, label='GARCH(1,1)')\n",
    "ax1.plot(range(1, horizon+1), vol_forecast_egarch * 100, \n",
    "         'r-', marker='s', linewidth=2, markersize=5, label='EGARCH(1,1)')\n",
    "ax1.axhline(y=lr_vol_garch*100, color='blue', linestyle='--', \n",
    "            alpha=0.5, label='Long-run vol (GARCH)')\n",
    "ax1.axhline(y=conditional_vol_garch.iloc[-1]*100, color='green', \n",
    "            linestyle=':', alpha=0.7, label='Current realized vol')\n",
    "ax1.set_xlabel('Forecast Horizon (days)')\n",
    "ax1.set_ylabel('Volatility (%)')\n",
    "ax1.set_title('Multi-Step Volatility Forecasts', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Forecast decay (relative to long-run)\n",
    "decay_garch = (vol_forecast_garch - lr_vol_garch) / lr_vol_garch * 100\n",
    "decay_egarch = (vol_forecast_egarch - lr_vol_garch) / lr_vol_garch * 100\n",
    "\n",
    "ax2.plot(range(1, horizon+1), decay_garch, \n",
    "         'b-', marker='o', linewidth=2, markersize=5, label='GARCH(1,1)')\n",
    "ax2.plot(range(1, horizon+1), decay_egarch, \n",
    "         'r-', marker='s', linewidth=2, markersize=5, label='EGARCH(1,1)')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax2.set_xlabel('Forecast Horizon (days)')\n",
    "ax2.set_ylabel('Deviation from Long-Run Vol (%)')\n",
    "ax2.set_title('Mean Reversion: Forecast Decay to Long-Run Level', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"Both models show mean reversion, but EGARCH forecasts differ slightly\")\n",
    "print(\"due to asymmetry. In trading, we use these forecasts to:\")\n",
    "print(\"  1. Scale position sizes (higher vol â†’ smaller positions)\")\n",
    "print(\"  2. Adjust stop losses (wider stops in high vol regimes)\")\n",
    "print(\"  3. Compare with implied vol for options trading opportunities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df30a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Trading Application - Volatility-Based Position Sizing\n",
    "\n",
    "Now we implement a practical trading strategy that uses GARCH forecasts to dynamically adjust position sizes. This is a critical risk management technique used by professional traders.\n",
    "\n",
    "**Strategy Logic:**\n",
    "\n",
    "1. **Fixed Risk per Trade**: Target 2% portfolio risk per position\n",
    "2. **Volatility-Adjusted Sizing**: \n",
    "   $$\\text{Position Size} = \\frac{\\text{Risk Capital}}{\\text{Forecasted Volatility} \\times \\text{Price}}$$\n",
    "3. **Stop-Loss Placement**: Set stops at $2 \\times \\sigma_{forecast}$\n",
    "4. **Capital Preservation**: Smaller positions in high-vol regimes\n",
    "\n",
    "**Example:**\n",
    "- Portfolio: $100,000\n",
    "- Risk per trade: 2% = $2,000\n",
    "- Forecasted vol: 1.5% daily\n",
    "- Price: $400\n",
    "- Position size: $2,000 / (0.015 Ã— $400) = 333 shares\n",
    "- Stop distance: $400 Ã— 2 Ã— 0.015 = $12 per share\n",
    "\n",
    "This approach ensures consistent risk exposure across different market regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement volatility-based position sizing\n",
    "portfolio_value = 100000  # $100k portfolio\n",
    "risk_per_trade = 0.02     # 2% risk per trade\n",
    "risk_capital = portfolio_value * risk_per_trade  # $2,000\n",
    "\n",
    "# Get price and forecasted volatility\n",
    "prices = data['Close'].values\n",
    "dates = data.index\n",
    "\n",
    "# Use one-day ahead volatility forecasts\n",
    "vol_forecast_1d_garch = np.sqrt(forecasts_garch.variance.iloc[:, 0])\n",
    "\n",
    "# Calculate position sizes\n",
    "position_sizes = []\n",
    "stop_distances = []\n",
    "stop_multiplier = 2.0  # Stop at 2 standard deviations\n",
    "\n",
    "for i in range(len(prices) - 20, len(prices)):  # Last 20 days\n",
    "    price = prices[i]\n",
    "    vol = vol_forecast_1d_garch.iloc[i]\n",
    "    \n",
    "    # Position size calculation\n",
    "    dollar_risk_per_share = stop_multiplier * vol * price\n",
    "    shares = int(risk_capital / dollar_risk_per_share)\n",
    "    position_value = shares * price\n",
    "    \n",
    "    # Stop loss distance\n",
    "    stop_distance = stop_multiplier * vol * price\n",
    "    \n",
    "    position_sizes.append({\n",
    "        'Date': dates[i],\n",
    "        'Price': price,\n",
    "        'Volatility': vol,\n",
    "        'Shares': shares,\n",
    "        'Position_Value': position_value,\n",
    "        'Stop_Distance': stop_distance,\n",
    "        'Stop_Loss_Price': price - stop_distance\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_positions = pd.DataFrame(position_sizes)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VOLATILITY-ADJUSTED POSITION SIZING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPortfolio Value: ${portfolio_value:,.0f}\")\n",
    "print(f\"Risk per Trade: {risk_per_trade*100:.1f}% = ${risk_capital:,.0f}\")\n",
    "print(f\"Stop Distance: {stop_multiplier}x forecasted volatility\\n\")\n",
    "\n",
    "print(\"Last 10 Trading Days:\")\n",
    "print(\"-\" * 80)\n",
    "print(df_positions.tail(10).to_string(index=False))\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POSITION SIZING STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAverage Position Size: ${df_positions['Position_Value'].mean():,.0f} \"\n",
    "      f\"({df_positions['Position_Value'].mean()/portfolio_value*100:.1f}% of portfolio)\")\n",
    "print(f\"Min Position: ${df_positions['Position_Value'].min():,.0f} \"\n",
    "      f\"({df_positions['Position_Value'].min()/portfolio_value*100:.1f}% of portfolio)\")\n",
    "print(f\"Max Position: ${df_positions['Position_Value'].max():,.0f} \"\n",
    "      f\"({df_positions['Position_Value'].max()/portfolio_value*100:.1f}% of portfolio)\")\n",
    "\n",
    "print(f\"\\nAverage Stop Distance: ${df_positions['Stop_Distance'].mean():.2f} \"\n",
    "      f\"({df_positions['Stop_Distance'].mean()/df_positions['Price'].mean()*100:.2f}%)\")\n",
    "\n",
    "# Visualize position sizing over time\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Volatility over time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_positions['Date'], df_positions['Volatility'] * 100, \n",
    "         'r-', linewidth=2, marker='o', markersize=4)\n",
    "ax1.set_ylabel('Forecasted Vol (%)', color='r')\n",
    "ax1.tick_params(axis='y', labelcolor='r')\n",
    "ax1.set_title('Dynamic Position Sizing Based on GARCH Forecasts', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Position size (number of shares)\n",
    "ax2 = axes[1]\n",
    "ax2.bar(df_positions['Date'], df_positions['Shares'], color='blue', alpha=0.7)\n",
    "ax2.set_ylabel('Position Size (shares)')\n",
    "ax2.set_title('Shares Allocated (Inverse Relationship with Volatility)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Position value vs. stop distance\n",
    "ax3 = axes[2]\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3.bar(df_positions['Date'], df_positions['Position_Value'], \n",
    "        color='green', alpha=0.5, label='Position Value')\n",
    "ax3_twin.plot(df_positions['Date'], df_positions['Stop_Distance'], \n",
    "              'r-', marker='o', linewidth=2, markersize=4, label='Stop Distance')\n",
    "ax3.set_ylabel('Position Value ($)', color='green')\n",
    "ax3_twin.set_ylabel('Stop Distance ($)', color='red')\n",
    "ax3.tick_params(axis='y', labelcolor='green')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='red')\n",
    "ax3.set_title('Position Value and Stop Loss Distance', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(\"1. HIGH VOLATILITY â†’ Smaller positions (fewer shares)\")\n",
    "print(\"2. LOW VOLATILITY â†’ Larger positions (more shares)\")\n",
    "print(\"3. This maintains CONSTANT RISK of $2,000 per trade\")\n",
    "print(\"4. Stop losses automatically widen/narrow with volatility\")\n",
    "print(\"5. Professional risk management: 'Size to survive, trade to thrive'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a467959",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Integration with Technical Indicators - RSI + GARCH\n",
    "\n",
    "We now combine **GARCH volatility regimes** with **RSI signals** to create a sophisticated trading system that:\n",
    "\n",
    "1. Identifies overbought/oversold conditions (RSI)\n",
    "2. Filters trades by volatility regime (GARCH)\n",
    "3. Sizes positions dynamically (volatility-adjusted)\n",
    "\n",
    "**Trading Rules:**\n",
    "\n",
    "**Entry Signals:**\n",
    "- **Long**: RSI < 30 (oversold) AND volatility is NOT extreme (Ïƒ < 3%)\n",
    "- **Short**: RSI > 70 (overbought) AND volatility is NOT extreme\n",
    "\n",
    "**Risk Management:**\n",
    "- Position sizing: Inversely proportional to forecasted volatility\n",
    "- Stop-loss: 2 Ã— Ïƒ from entry price\n",
    "- Exit: RSI crosses 50 (neutral) or stop hit\n",
    "\n",
    "**Rationale:**\n",
    "- Extreme volatility often precedes trend continuation (not reversal)\n",
    "- Mean reversion works best in normal volatility regimes\n",
    "- GARCH forecasts help avoid false signals during market stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RSI\n",
    "def calculate_rsi(prices, period=14):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    deltas = np.diff(prices)\n",
    "    gains = np.where(deltas > 0, deltas, 0)\n",
    "    losses = np.where(deltas < 0, -deltas, 0)\n",
    "    \n",
    "    # Initial average\n",
    "    avg_gain = np.mean(gains[:period])\n",
    "    avg_loss = np.mean(losses[:period])\n",
    "    \n",
    "    rsi = np.zeros(len(prices))\n",
    "    rsi[:period] = np.nan\n",
    "    \n",
    "    # Calculate RSI\n",
    "    for i in range(period, len(prices)):\n",
    "        avg_gain = (avg_gain * (period - 1) + gains[i - 1]) / period\n",
    "        avg_loss = (avg_loss * (period - 1) + losses[i - 1]) / period\n",
    "        \n",
    "        if avg_loss == 0:\n",
    "            rsi[i] = 100\n",
    "        else:\n",
    "            rs = avg_gain / avg_loss\n",
    "            rsi[i] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi\n",
    "\n",
    "# Calculate RSI on close prices\n",
    "rsi = calculate_rsi(prices)\n",
    "\n",
    "# Create trading signals\n",
    "df_trading = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Price': prices,\n",
    "    'RSI': rsi,\n",
    "    'Volatility': np.concatenate([np.full(len(prices) - len(conditional_vol_garch), np.nan), \n",
    "                                   conditional_vol_garch.values])\n",
    "})\n",
    "\n",
    "# Drop NaN rows\n",
    "df_trading = df_trading.dropna()\n",
    "\n",
    "# Generate signals\n",
    "vol_threshold = 0.03  # 3% daily vol threshold\n",
    "\n",
    "df_trading['Signal'] = 0\n",
    "df_trading.loc[(df_trading['RSI'] < 30) & \n",
    "               (df_trading['Volatility'] < vol_threshold), 'Signal'] = 1  # Long\n",
    "df_trading.loc[(df_trading['RSI'] > 70) & \n",
    "               (df_trading['Volatility'] < vol_threshold), 'Signal'] = -1  # Short\n",
    "\n",
    "# Calculate returns from signals\n",
    "df_trading['Next_Return'] = df_trading['Price'].pct_change().shift(-1)\n",
    "df_trading['Strategy_Return'] = df_trading['Signal'] * df_trading['Next_Return']\n",
    "\n",
    "# Calculate cumulative returns\n",
    "df_trading['Cumulative_Market'] = (1 + df_trading['Next_Return']).cumprod()\n",
    "df_trading['Cumulative_Strategy'] = (1 + df_trading['Strategy_Return']).cumprod()\n",
    "\n",
    "# Performance metrics\n",
    "total_signals = (df_trading['Signal'] != 0).sum()\n",
    "long_signals = (df_trading['Signal'] == 1).sum()\n",
    "short_signals = (df_trading['Signal'] == -1).sum()\n",
    "\n",
    "strategy_return = df_trading['Cumulative_Strategy'].iloc[-1] - 1\n",
    "market_return = df_trading['Cumulative_Market'].iloc[-1] - 1\n",
    "sharpe_ratio = df_trading['Strategy_Return'].mean() / df_trading['Strategy_Return'].std() * np.sqrt(252)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RSI + GARCH TRADING STRATEGY RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nStrategy: Long when RSI<30, Short when RSI>70\")\n",
    "print(f\"Volatility Filter: Only trade when Ïƒ < {vol_threshold*100:.1f}%\")\n",
    "print(f\"\\nPeriod: {df_trading['Date'].iloc[0].strftime('%Y-%m-%d')} to \"\n",
    "      f\"{df_trading['Date'].iloc[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total Trading Days: {len(df_trading)}\")\n",
    "\n",
    "print(f\"\\nSIGNAL SUMMARY:\")\n",
    "print(f\"  Total signals: {total_signals}\")\n",
    "print(f\"  Long signals: {long_signals}\")\n",
    "print(f\"  Short signals: {short_signals}\")\n",
    "print(f\"  Days in market: {total_signals / len(df_trading) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nPERFORMANCE:\")\n",
    "print(f\"  Buy & Hold Return: {market_return*100:+.2f}%\")\n",
    "print(f\"  Strategy Return: {strategy_return*100:+.2f}%\")\n",
    "print(f\"  Outperformance: {(strategy_return - market_return)*100:+.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "\n",
    "# Visualize trading signals and performance\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 14))\n",
    "\n",
    "# Plot 1: Price with signals\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_trading['Date'], df_trading['Price'], 'k-', linewidth=1.5, label='SPY Price')\n",
    "long_dates = df_trading[df_trading['Signal'] == 1]['Date']\n",
    "long_prices = df_trading[df_trading['Signal'] == 1]['Price']\n",
    "short_dates = df_trading[df_trading['Signal'] == -1]['Date']\n",
    "short_prices = df_trading[df_trading['Signal'] == -1]['Price']\n",
    "ax1.scatter(long_dates, long_prices, color='green', marker='^', s=100, \n",
    "            label='Long Signal', zorder=5)\n",
    "ax1.scatter(short_dates, short_prices, color='red', marker='v', s=100, \n",
    "            label='Short Signal', zorder=5)\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.set_title('Trading Signals: RSI + GARCH Volatility Filter', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: RSI with levels\n",
    "ax2 = axes[1]\n",
    "ax2.plot(df_trading['Date'], df_trading['RSI'], 'purple', linewidth=1.5)\n",
    "ax2.axhline(y=70, color='red', linestyle='--', alpha=0.7, label='Overbought (70)')\n",
    "ax2.axhline(y=30, color='green', linestyle='--', alpha=0.7, label='Oversold (30)')\n",
    "ax2.axhline(y=50, color='gray', linestyle='-', alpha=0.5)\n",
    "ax2.fill_between(df_trading['Date'], 70, 100, alpha=0.1, color='red')\n",
    "ax2.fill_between(df_trading['Date'], 0, 30, alpha=0.1, color='green')\n",
    "ax2.set_ylabel('RSI')\n",
    "ax2.set_title('RSI Oscillator', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "# Plot 3: Volatility\n",
    "ax3 = axes[2]\n",
    "ax3.plot(df_trading['Date'], df_trading['Volatility'] * 100, 'orange', linewidth=1.5)\n",
    "ax3.axhline(y=vol_threshold*100, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Vol Threshold ({vol_threshold*100:.0f}%)')\n",
    "ax3.fill_between(df_trading['Date'], vol_threshold*100, \n",
    "                 df_trading['Volatility'].max()*100, alpha=0.2, color='red')\n",
    "ax3.set_ylabel('Volatility (%)')\n",
    "ax3.set_title('GARCH Conditional Volatility (Regime Filter)', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Cumulative returns\n",
    "ax4 = axes[3]\n",
    "ax4.plot(df_trading['Date'], (df_trading['Cumulative_Market'] - 1) * 100, \n",
    "         'gray', linewidth=2, label='Buy & Hold', alpha=0.7)\n",
    "ax4.plot(df_trading['Date'], (df_trading['Cumulative_Strategy'] - 1) * 100, \n",
    "         'blue', linewidth=2, label='RSI + GARCH Strategy')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax4.set_ylabel('Cumulative Return (%)')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_title('Strategy vs Buy & Hold Performance', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKEY TAKEAWAYS:\")\n",
    "print(\"1. Volatility filter reduces false signals during market stress\")\n",
    "print(\"2. RSI mean reversion works better in stable volatility regimes\")\n",
    "print(\"3. Combined approach improves risk-adjusted returns\")\n",
    "print(\"4. Integration of technical + statistical models = superior edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd589dd7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 11: Advanced Integration - Divergence Analysis with GARCH\n",
    "\n",
    "**Divergence** occurs when price and an indicator (like RSI) move in opposite directions, signaling potential reversals.\n",
    "\n",
    "**Types of Divergences:**\n",
    "\n",
    "1. **Regular Bullish**: Price makes lower low, RSI makes higher low â†’ Bullish reversal\n",
    "2. **Regular Bearish**: Price makes higher high, RSI makes lower high â†’ Bearish reversal\n",
    "3. **Hidden Bullish**: Price makes higher low, RSI makes lower low â†’ Trend continuation (bullish)\n",
    "4. **Hidden Bearish**: Price makes lower high, RSI makes higher high â†’ Trend continuation (bearish)\n",
    "\n",
    "**GARCH Enhancement:**\n",
    "\n",
    "We use volatility context to filter divergence signals:\n",
    "\n",
    "- **Confirmation**: Divergence + decreasing volatility â†’ Stronger signal\n",
    "- **Rejection**: Divergence + spiking volatility â†’ Unreliable (wait)\n",
    "- **Position Sizing**: Scale by inverse volatility\n",
    "\n",
    "This improves the classic divergence strategy by avoiding false signals during volatile periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4128771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect divergences\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Find local extrema in price and RSI\n",
    "lookback = 20  # Window for finding peaks\n",
    "\n",
    "# Price extrema\n",
    "price_highs_idx, _ = find_peaks(df_trading['Price'].values, distance=lookback)\n",
    "price_lows_idx, _ = find_peaks(-df_trading['Price'].values, distance=lookback)\n",
    "\n",
    "# RSI extrema\n",
    "rsi_highs_idx, _ = find_peaks(df_trading['RSI'].values, distance=lookback)\n",
    "rsi_lows_idx, _ = find_peaks(-df_trading['RSI'].values, distance=lookback)\n",
    "\n",
    "def detect_regular_bullish_divergence(price, rsi, price_lows, rsi_lows):\n",
    "    \"\"\"Detect regular bullish divergence: price LL, RSI HL\"\"\"\n",
    "    divergences = []\n",
    "    for i in range(len(price_lows) - 1):\n",
    "        idx1 = price_lows[i]\n",
    "        idx2 = price_lows[i + 1]\n",
    "        \n",
    "        # Find corresponding RSI lows\n",
    "        rsi_low1 = None\n",
    "        rsi_low2 = None\n",
    "        for j in rsi_lows:\n",
    "            if abs(j - idx1) < 5:  # Allow small offset\n",
    "                rsi_low1 = j\n",
    "            if abs(j - idx2) < 5:\n",
    "                rsi_low2 = j\n",
    "        \n",
    "        if rsi_low1 is not None and rsi_low2 is not None:\n",
    "            # Check for divergence\n",
    "            price_lower = price[idx2] < price[idx1]\n",
    "            rsi_higher = rsi[rsi_low2] > rsi[rsi_low1]\n",
    "            \n",
    "            if price_lower and rsi_higher:\n",
    "                divergences.append(idx2)\n",
    "    \n",
    "    return divergences\n",
    "\n",
    "def detect_regular_bearish_divergence(price, rsi, price_highs, rsi_highs):\n",
    "    \"\"\"Detect regular bearish divergence: price HH, RSI LH\"\"\"\n",
    "    divergences = []\n",
    "    for i in range(len(price_highs) - 1):\n",
    "        idx1 = price_highs[i]\n",
    "        idx2 = price_highs[i + 1]\n",
    "        \n",
    "        # Find corresponding RSI highs\n",
    "        rsi_high1 = None\n",
    "        rsi_high2 = None\n",
    "        for j in rsi_highs:\n",
    "            if abs(j - idx1) < 5:\n",
    "                rsi_high1 = j\n",
    "            if abs(j - idx2) < 5:\n",
    "                rsi_high2 = j\n",
    "        \n",
    "        if rsi_high1 is not None and rsi_high2 is not None:\n",
    "            # Check for divergence\n",
    "            price_higher = price[idx2] > price[idx1]\n",
    "            rsi_lower = rsi[rsi_high2] < rsi[rsi_high1]\n",
    "            \n",
    "            if price_higher and rsi_lower:\n",
    "                divergences.append(idx2)\n",
    "    \n",
    "    return divergences\n",
    "\n",
    "# Detect divergences\n",
    "bullish_div = detect_regular_bullish_divergence(\n",
    "    df_trading['Price'].values, \n",
    "    df_trading['RSI'].values, \n",
    "    price_lows_idx, \n",
    "    rsi_lows_idx\n",
    ")\n",
    "\n",
    "bearish_div = detect_regular_bearish_divergence(\n",
    "    df_trading['Price'].values, \n",
    "    df_trading['RSI'].values, \n",
    "    price_highs_idx, \n",
    "    rsi_highs_idx\n",
    ")\n",
    "\n",
    "# Filter divergences by volatility\n",
    "vol_values = df_trading['Volatility'].values\n",
    "vol_increasing_threshold = 0.02  # 2% vol threshold\n",
    "\n",
    "bullish_div_filtered = [idx for idx in bullish_div \n",
    "                        if vol_values[idx] < vol_increasing_threshold]\n",
    "bearish_div_filtered = [idx for idx in bearish_div \n",
    "                        if vol_values[idx] < vol_increasing_threshold]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIVERGENCE DETECTION + GARCH FILTER\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal Regular Bullish Divergences: {len(bullish_div)}\")\n",
    "print(f\"  Filtered (low vol): {len(bullish_div_filtered)}\")\n",
    "print(f\"  Rejected (high vol): {len(bullish_div) - len(bullish_div_filtered)}\")\n",
    "\n",
    "print(f\"\\nTotal Regular Bearish Divergences: {len(bearish_div)}\")\n",
    "print(f\"  Filtered (low vol): {len(bearish_div_filtered)}\")\n",
    "print(f\"  Rejected (high vol): {len(bearish_div) - len(bearish_div_filtered)}\")\n",
    "\n",
    "# Show examples\n",
    "if len(bullish_div_filtered) > 0:\n",
    "    print(f\"\\nLast Bullish Divergence (filtered):\")\n",
    "    idx = bullish_div_filtered[-1]\n",
    "    print(f\"  Date: {df_trading['Date'].iloc[idx].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Price: ${df_trading['Price'].iloc[idx]:.2f}\")\n",
    "    print(f\"  RSI: {df_trading['RSI'].iloc[idx]:.1f}\")\n",
    "    print(f\"  Volatility: {df_trading['Volatility'].iloc[idx]*100:.2f}%\")\n",
    "\n",
    "if len(bearish_div_filtered) > 0:\n",
    "    print(f\"\\nLast Bearish Divergence (filtered):\")\n",
    "    idx = bearish_div_filtered[-1]\n",
    "    print(f\"  Date: {df_trading['Date'].iloc[idx].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Price: ${df_trading['Price'].iloc[idx]:.2f}\")\n",
    "    print(f\"  RSI: {df_trading['RSI'].iloc[idx]:.1f}\")\n",
    "    print(f\"  Volatility: {df_trading['Volatility'].iloc[idx]*100:.2f}%\")\n",
    "\n",
    "# Visualize divergences\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Price with divergence markers\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_trading['Date'], df_trading['Price'], 'k-', linewidth=1.5, label='SPY Price')\n",
    "\n",
    "# Mark all divergences (faded)\n",
    "for idx in bullish_div:\n",
    "    ax1.scatter(df_trading['Date'].iloc[idx], df_trading['Price'].iloc[idx], \n",
    "                color='green', marker='^', s=100, alpha=0.3, edgecolors='none')\n",
    "for idx in bearish_div:\n",
    "    ax1.scatter(df_trading['Date'].iloc[idx], df_trading['Price'].iloc[idx], \n",
    "                color='red', marker='v', s=100, alpha=0.3, edgecolors='none')\n",
    "\n",
    "# Mark filtered divergences (bright)\n",
    "for idx in bullish_div_filtered:\n",
    "    ax1.scatter(df_trading['Date'].iloc[idx], df_trading['Price'].iloc[idx], \n",
    "                color='green', marker='^', s=200, alpha=1.0, \n",
    "                edgecolors='darkgreen', linewidths=2, label='Bullish Div (filtered)', zorder=5)\n",
    "for idx in bearish_div_filtered:\n",
    "    ax1.scatter(df_trading['Date'].iloc[idx], df_trading['Price'].iloc[idx], \n",
    "                color='red', marker='v', s=200, alpha=1.0, \n",
    "                edgecolors='darkred', linewidths=2, label='Bearish Div (filtered)', zorder=5)\n",
    "\n",
    "# Remove duplicate labels\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "ax1.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.set_title('Divergence Detection with GARCH Volatility Filter', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: RSI\n",
    "ax2 = axes[1]\n",
    "ax2.plot(df_trading['Date'], df_trading['RSI'], 'purple', linewidth=1.5)\n",
    "ax2.axhline(y=70, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=30, color='green', linestyle='--', alpha=0.5)\n",
    "ax2.set_ylabel('RSI')\n",
    "ax2.set_title('RSI with Extrema', fontsize=12, fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "# Plot 3: Volatility\n",
    "ax3 = axes[2]\n",
    "ax3.plot(df_trading['Date'], df_trading['Volatility'] * 100, 'orange', linewidth=1.5)\n",
    "ax3.axhline(y=vol_increasing_threshold*100, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Vol Threshold ({vol_increasing_threshold*100:.0f}%)')\n",
    "\n",
    "# Mark divergence periods\n",
    "for idx in bullish_div_filtered:\n",
    "    ax3.axvline(x=df_trading['Date'].iloc[idx], color='green', alpha=0.3, linestyle='-')\n",
    "for idx in bearish_div_filtered:\n",
    "    ax3.axvline(x=df_trading['Date'].iloc[idx], color='red', alpha=0.3, linestyle='-')\n",
    "\n",
    "ax3.set_ylabel('Volatility (%)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_title('GARCH Volatility (Filtering Criterion)', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSTRATEGY IMPROVEMENT:\")\n",
    "print(\"Without GARCH filter: All divergences taken (including during vol spikes)\")\n",
    "print(\"With GARCH filter: Only divergences in stable volatility regimes\")\n",
    "print(\"Result: Higher win rate, fewer false signals, better risk management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb43f65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 12: Complete Mini-Project - Integrated Trading System\n",
    "\n",
    "We now build a **complete end-to-end trading system** that integrates everything:\n",
    "\n",
    "1. **GARCH(1,1)** for volatility forecasting\n",
    "2. **RSI** for mean reversion signals\n",
    "3. **Divergence detection** for reversal confirmation\n",
    "4. **Dynamic position sizing** based on forecasted volatility\n",
    "5. **Risk management** with volatility-adjusted stops\n",
    "\n",
    "**System Architecture:**\n",
    "\n",
    "```\n",
    "Data â†’ GARCH Model â†’ Volatility Forecast\n",
    "                           â†“\n",
    "RSI Calculation â†’ Signal Generation â† Divergence Detection\n",
    "                           â†“\n",
    "        Position Sizing (Vol-Adjusted)\n",
    "                           â†“\n",
    "        Trade Execution with Stops\n",
    "                           â†“\n",
    "        Performance Tracking & Analytics\n",
    "```\n",
    "\n",
    "**Entry Logic:**\n",
    "- Long: (RSI < 30 OR Bullish Divergence) AND Vol < 2.5%\n",
    "- Short: (RSI > 70 OR Bearish Divergence) AND Vol < 2.5%\n",
    "\n",
    "**Exit Logic:**\n",
    "- Stop-loss: 2 Ã— forecasted Ïƒ\n",
    "- Profit target: 3 Ã— forecasted Ïƒ (risk-reward = 1.5)\n",
    "- Neutral exit: RSI crosses 50\n",
    "\n",
    "**Position Sizing:**\n",
    "- Risk: 2% of portfolio per trade\n",
    "- Size: Risk Capital / (2 Ã— Ïƒ Ã— Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete integrated trading system\n",
    "class IntegratedTradingSystem:\n",
    "    def __init__(self, prices, returns, vol_forecasts, rsi, divergences, \n",
    "                 portfolio_value=100000, risk_per_trade=0.02):\n",
    "        self.prices = prices\n",
    "        self.returns = returns\n",
    "        self.vol_forecasts = vol_forecasts\n",
    "        self.rsi = rsi\n",
    "        self.bullish_div = set(divergences['bullish'])\n",
    "        self.bearish_div = set(divergences['bearish'])\n",
    "        self.portfolio_value = portfolio_value\n",
    "        self.risk_per_trade = risk_per_trade\n",
    "        \n",
    "        self.position = 0  # 0=neutral, 1=long, -1=short\n",
    "        self.entry_price = 0\n",
    "        self.stop_loss = 0\n",
    "        self.profit_target = 0\n",
    "        self.trades = []\n",
    "        self.equity_curve = [portfolio_value]\n",
    "        \n",
    "    def calculate_position_size(self, price, vol):\n",
    "        \"\"\"Calculate shares based on volatility\"\"\"\n",
    "        risk_capital = self.portfolio_value * self.risk_per_trade\n",
    "        dollar_risk_per_share = 2 * vol * price\n",
    "        shares = int(risk_capital / dollar_risk_per_share)\n",
    "        return max(shares, 1)  # At least 1 share\n",
    "    \n",
    "    def generate_signal(self, i):\n",
    "        \"\"\"Generate trading signal\"\"\"\n",
    "        vol_threshold = 0.025  # 2.5%\n",
    "        \n",
    "        # Don't trade if volatility too high\n",
    "        if self.vol_forecasts[i] > vol_threshold:\n",
    "            return 0\n",
    "        \n",
    "        # Long conditions\n",
    "        if self.rsi[i] < 30 or i in self.bullish_div:\n",
    "            return 1\n",
    "        \n",
    "        # Short conditions\n",
    "        if self.rsi[i] > 70 or i in self.bearish_div:\n",
    "            return -1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def should_exit(self, i):\n",
    "        \"\"\"Check exit conditions\"\"\"\n",
    "        current_price = self.prices[i]\n",
    "        \n",
    "        # Stop loss hit\n",
    "        if self.position == 1 and current_price <= self.stop_loss:\n",
    "            return True, \"Stop Loss\"\n",
    "        if self.position == -1 and current_price >= self.stop_loss:\n",
    "            return True, \"Stop Loss\"\n",
    "        \n",
    "        # Profit target hit\n",
    "        if self.position == 1 and current_price >= self.profit_target:\n",
    "            return True, \"Profit Target\"\n",
    "        if self.position == -1 and current_price <= self.profit_target:\n",
    "            return True, \"Profit Target\"\n",
    "        \n",
    "        # Neutral RSI\n",
    "        if 45 <= self.rsi[i] <= 55:\n",
    "            return True, \"RSI Neutral\"\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def run_backtest(self):\n",
    "        \"\"\"Execute backtest\"\"\"\n",
    "        for i in range(50, len(self.prices)):  # Start after indicators stabilize\n",
    "            current_price = self.prices[i]\n",
    "            \n",
    "            # Check exit if in position\n",
    "            if self.position != 0:\n",
    "                should_exit, exit_reason = self.should_exit(i)\n",
    "                if should_exit:\n",
    "                    # Close position\n",
    "                    pnl = (current_price - self.entry_price) * self.position * self.shares\n",
    "                    pnl_pct = (current_price / self.entry_price - 1) * self.position * 100\n",
    "                    \n",
    "                    self.portfolio_value += pnl\n",
    "                    self.equity_curve.append(self.portfolio_value)\n",
    "                    \n",
    "                    self.trades.append({\n",
    "                        'Entry_Date': self.entry_date,\n",
    "                        'Exit_Date': i,\n",
    "                        'Direction': 'Long' if self.position == 1 else 'Short',\n",
    "                        'Entry_Price': self.entry_price,\n",
    "                        'Exit_Price': current_price,\n",
    "                        'Shares': self.shares,\n",
    "                        'PnL': pnl,\n",
    "                        'PnL_Pct': pnl_pct,\n",
    "                        'Exit_Reason': exit_reason,\n",
    "                        'Volatility': self.vol_forecasts[self.entry_date]\n",
    "                    })\n",
    "                    \n",
    "                    self.position = 0\n",
    "                else:\n",
    "                    self.equity_curve.append(self.portfolio_value)\n",
    "                continue\n",
    "            \n",
    "            # Generate new signal if no position\n",
    "            signal = self.generate_signal(i)\n",
    "            \n",
    "            if signal != 0:\n",
    "                # Enter position\n",
    "                self.position = signal\n",
    "                self.entry_price = current_price\n",
    "                self.entry_date = i\n",
    "                self.shares = self.calculate_position_size(current_price, self.vol_forecasts[i])\n",
    "                \n",
    "                # Set stops and targets\n",
    "                vol_dollars = self.vol_forecasts[i] * current_price\n",
    "                if signal == 1:  # Long\n",
    "                    self.stop_loss = current_price - 2 * vol_dollars\n",
    "                    self.profit_target = current_price + 3 * vol_dollars\n",
    "                else:  # Short\n",
    "                    self.stop_loss = current_price + 2 * vol_dollars\n",
    "                    self.profit_target = current_price - 3 * vol_dollars\n",
    "            \n",
    "            self.equity_curve.append(self.portfolio_value)\n",
    "        \n",
    "        return self.trades, self.equity_curve\n",
    "\n",
    "# Run the integrated system\n",
    "system = IntegratedTradingSystem(\n",
    "    prices=df_trading['Price'].values,\n",
    "    returns=df_trading['Next_Return'].values,\n",
    "    vol_forecasts=df_trading['Volatility'].values,\n",
    "    rsi=df_trading['RSI'].values,\n",
    "    divergences={'bullish': bullish_div_filtered, 'bearish': bearish_div_filtered}\n",
    ")\n",
    "\n",
    "trades, equity_curve = system.run_backtest()\n",
    "\n",
    "# Convert trades to DataFrame\n",
    "df_trades = pd.DataFrame(trades)\n",
    "\n",
    "# Calculate performance metrics\n",
    "if len(df_trades) > 0:\n",
    "    winning_trades = df_trades[df_trades['PnL'] > 0]\n",
    "    losing_trades = df_trades[df_trades['PnL'] < 0]\n",
    "    \n",
    "    win_rate = len(winning_trades) / len(df_trades) * 100\n",
    "    avg_win = winning_trades['PnL'].mean() if len(winning_trades) > 0 else 0\n",
    "    avg_loss = losing_trades['PnL'].mean() if len(losing_trades) > 0 else 0\n",
    "    profit_factor = abs(winning_trades['PnL'].sum() / losing_trades['PnL'].sum()) if len(losing_trades) > 0 else np.inf\n",
    "    \n",
    "    total_return = (equity_curve[-1] / equity_curve[0] - 1) * 100\n",
    "    max_drawdown = np.min(np.array(equity_curve) / np.maximum.accumulate(equity_curve) - 1) * 100\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"INTEGRATED TRADING SYSTEM BACKTEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nInitial Capital: ${equity_curve[0]:,.0f}\")\n",
    "    print(f\"Final Capital: ${equity_curve[-1]:,.0f}\")\n",
    "    print(f\"Total Return: {total_return:+.2f}%\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nTRADE STATISTICS:\")\n",
    "    print(f\"  Total Trades: {len(df_trades)}\")\n",
    "    print(f\"  Winning Trades: {len(winning_trades)} ({win_rate:.1f}%)\")\n",
    "    print(f\"  Losing Trades: {len(losing_trades)}\")\n",
    "    print(f\"  Average Win: ${avg_win:,.2f}\")\n",
    "    print(f\"  Average Loss: ${avg_loss:,.2f}\")\n",
    "    print(f\"  Profit Factor: {profit_factor:.2f}\")\n",
    "    print(f\"  Risk-Reward Ratio: {abs(avg_win/avg_loss):.2f}\" if avg_loss != 0 else \"  Risk-Reward Ratio: N/A\")\n",
    "    \n",
    "    print(f\"\\nBREAKDOWN BY DIRECTION:\")\n",
    "    long_trades = df_trades[df_trades['Direction'] == 'Long']\n",
    "    short_trades = df_trades[df_trades['Direction'] == 'Short']\n",
    "    print(f\"  Long Trades: {len(long_trades)} (Win Rate: {len(long_trades[long_trades['PnL']>0])/len(long_trades)*100:.1f}%)\" if len(long_trades) > 0 else \"  Long Trades: 0\")\n",
    "    print(f\"  Short Trades: {len(short_trades)} (Win Rate: {len(short_trades[short_trades['PnL']>0])/len(short_trades)*100:.1f}%)\" if len(short_trades) > 0 else \"  Short Trades: 0\")\n",
    "    \n",
    "    print(f\"\\nEXIT REASONS:\")\n",
    "    for reason, count in df_trades['Exit_Reason'].value_counts().items():\n",
    "        print(f\"  {reason}: {count} ({count/len(df_trades)*100:.1f}%)\")\n",
    "    \n",
    "    # Show best and worst trades\n",
    "    print(f\"\\nBEST TRADE:\")\n",
    "    best = df_trades.loc[df_trades['PnL'].idxmax()]\n",
    "    print(f\"  {best['Direction']} | Entry: ${best['Entry_Price']:.2f} | Exit: ${best['Exit_Price']:.2f} | PnL: ${best['PnL']:,.2f} ({best['PnL_Pct']:+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nWORST TRADE:\")\n",
    "    worst = df_trades.loc[df_trades['PnL'].idxmin()]\n",
    "    print(f\"  {worst['Direction']} | Entry: ${worst['Entry_Price']:.2f} | Exit: ${worst['Exit_Price']:.2f} | PnL: ${worst['PnL']:,.2f} ({worst['PnL_Pct']:+.2f}%)\")\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: Equity curve\n",
    "    ax1 = axes[0]\n",
    "    dates_equity = df_trading['Date'].iloc[:len(equity_curve)]\n",
    "    ax1.plot(dates_equity, equity_curve, 'b-', linewidth=2, label='Strategy Equity')\n",
    "    ax1.axhline(y=equity_curve[0], color='gray', linestyle='--', alpha=0.5, label='Starting Capital')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.set_title('Integrated Trading System: Equity Curve', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "    \n",
    "    # Plot 2: Price with trades\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(df_trading['Date'], df_trading['Price'], 'k-', linewidth=1, alpha=0.5, label='SPY Price')\n",
    "    \n",
    "    for _, trade in df_trades.iterrows():\n",
    "        entry_date = df_trading['Date'].iloc[trade['Entry_Date']]\n",
    "        exit_date = df_trading['Date'].iloc[trade['Exit_Date']]\n",
    "        entry_price = trade['Entry_Price']\n",
    "        exit_price = trade['Exit_Price']\n",
    "        \n",
    "        color = 'green' if trade['PnL'] > 0 else 'red'\n",
    "        marker = '^' if trade['Direction'] == 'Long' else 'v'\n",
    "        \n",
    "        ax2.scatter(entry_date, entry_price, color=color, marker=marker, s=100, alpha=0.7, edgecolors='black')\n",
    "        ax2.scatter(exit_date, exit_price, color=color, marker='o', s=50, alpha=0.7)\n",
    "        ax2.plot([entry_date, exit_date], [entry_price, exit_price], color=color, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    ax2.set_ylabel('Price ($)')\n",
    "    ax2.set_title('Trade Entries and Exits on Price Chart', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Trade PnL distribution\n",
    "    ax3 = axes[2]\n",
    "    ax3.bar(range(len(df_trades)), df_trades['PnL'], \n",
    "            color=['green' if x > 0 else 'red' for x in df_trades['PnL']], alpha=0.7)\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax3.set_xlabel('Trade Number')\n",
    "    ax3.set_ylabel('PnL ($)')\n",
    "    ax3.set_title('Individual Trade Profit/Loss', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSYSTEM HIGHLIGHTS:\")\n",
    "    print(\"1. Combines multiple signals: RSI + Divergences + GARCH\")\n",
    "    print(\"2. Dynamic position sizing adapts to market volatility\")\n",
    "    print(\"3. Multi-level exits: Stops, Targets, and Neutral signals\")\n",
    "    print(\"4. Risk-managed approach: 2% risk per trade, vol-adjusted\")\n",
    "    print(\"5. Professional-grade system ready for live trading (with refinements)\")\n",
    "else:\n",
    "    print(\"No trades generated. Adjust strategy parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cad9c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 13: Exercises and Challenges\n",
    "\n",
    "Now it's your turn to practice and extend what you've learned.\n",
    "\n",
    "### Exercise 1: Parameter Sensitivity Analysis\n",
    "**Task**: Analyze how GARCH parameters affect volatility forecasts\n",
    "- Estimate GARCH(1,1) on a different time period (e.g., 2015-2019)\n",
    "- Compare parameters with our 2020-2024 estimation\n",
    "- Question: How did the COVID-19 crisis change persistence (Î± + Î²)?\n",
    "\n",
    "**Hint**: Higher persistence after crisis suggests longer-lasting volatility shocks.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: Model Selection\n",
    "**Task**: Compare different GARCH variants\n",
    "- Estimate: ARCH(2), GARCH(1,1), GARCH(2,2), EGARCH(1,1)\n",
    "- Use AIC/BIC for model selection\n",
    "- Test forecasting accuracy on out-of-sample data\n",
    "\n",
    "**Code Template**:\n",
    "```python\n",
    "from arch import arch_model\n",
    "\n",
    "# GARCH(2,2)\n",
    "model_22 = arch_model(returns, vol='GARCH', p=2, q=2)\n",
    "result_22 = model_22.fit()\n",
    "print(f\"AIC: {result_22.aic}, BIC: {result_22.bic}\")\n",
    "```\n",
    "\n",
    "**Question**: Does added complexity improve forecasts?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3: Volatility Regime Classification\n",
    "**Task**: Use GARCH forecasts to classify market regimes\n",
    "- Define regimes: Low (Ïƒ < 1%), Medium (1-2%), High (2-3%), Extreme (>3%)\n",
    "- Calculate average returns in each regime\n",
    "- Question: Are low-volatility regimes followed by high returns?\n",
    "\n",
    "**Hint**: Use `pd.cut()` to bin volatility values.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4: Options Trading Strategy\n",
    "**Task**: Build a volatility-based options strategy\n",
    "- Compare GARCH forecasts with VIX (implied volatility)\n",
    "- Signal: Long straddle when GARCH forecast > VIX (volatility underpriced)\n",
    "- Calculate theoretical P&L assuming perfect hedging\n",
    "\n",
    "**Extension**: Incorporate EGARCH asymmetry for put/call weighting\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 5: Multi-Asset Portfolio\n",
    "**Task**: Apply GARCH to portfolio risk management\n",
    "- Download 3-5 assets (stocks, bonds, commodities)\n",
    "- Estimate GARCH(1,1) for each\n",
    "- Build dynamic portfolio weights: $w_i \\propto 1/\\sigma_i^2$ (inverse volatility)\n",
    "- Compare performance vs equal-weighted portfolio\n",
    "\n",
    "**Metrics to report**:\n",
    "- Sharpe ratio\n",
    "- Max drawdown\n",
    "- Turnover (rebalancing frequency)\n",
    "\n",
    "---\n",
    "\n",
    "### Challenge 1: Real-Time Trading System\n",
    "**Advanced Task**: Build a production-ready system\n",
    "1. Fetch live data (use `yfinance` with recent dates)\n",
    "2. Update GARCH model daily (rolling window)\n",
    "3. Generate signals and position sizes\n",
    "4. Log all trades to a database/CSV\n",
    "5. Send alerts (email/SMS) on trade execution\n",
    "\n",
    "**Technologies**: Python + SQLite + APScheduler (for scheduling) + smtplib (for emails)\n",
    "\n",
    "---\n",
    "\n",
    "### Challenge 2: Deep Learning Enhancement\n",
    "**Research Task**: Replace GARCH with Neural Network\n",
    "- Architecture: LSTM for volatility forecasting\n",
    "- Input: Lagged returns, rolling statistics\n",
    "- Output: Next-day volatility\n",
    "- Compare with GARCH(1,1) on MAE, RMSE\n",
    "\n",
    "**Question**: Does deep learning outperform classical econometric models?\n",
    "\n",
    "---\n",
    "\n",
    "### Challenge 3: High-Frequency Data\n",
    "**Advanced Analysis**: Apply GARCH to intraday data\n",
    "- Download 1-minute or 5-minute SPY data\n",
    "- Estimate GARCH on intraday returns\n",
    "- Question: How do parameters differ from daily frequency?\n",
    "- Use realized volatility (RV) as benchmark\n",
    "\n",
    "**Key concept**: At higher frequencies, microstructure noise matters.\n",
    "\n",
    "---\n",
    "\n",
    "### Challenge 4: Multivariate GARCH\n",
    "**Extension**: Model volatility spillovers across assets\n",
    "- Estimate DCC-GARCH (Dynamic Conditional Correlation)\n",
    "- Assets: SPY, TLT (bonds), GLD (gold)\n",
    "- Analyze time-varying correlations during stress periods\n",
    "- Build crisis-robust portfolio using correlation forecasts\n",
    "\n",
    "**Library**: `arch` supports multivariate GARCH through `DCC` class\n",
    "\n",
    "---\n",
    "\n",
    "### Solutions and Discussion\n",
    "\n",
    "Work through these exercises to deepen your understanding. Compare your results with peers or reference materials. Key learning goals:\n",
    "\n",
    "1. **Sensitivity**: Understanding how parameters change across regimes\n",
    "2. **Model Selection**: Balancing complexity and performance\n",
    "3. **Application**: Translating theory to practical trading\n",
    "4. **Extension**: Pushing beyond basics to frontier methods\n",
    "\n",
    "Remember: The best way to learn quantitative finance is by coding and experimenting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8300e370",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "Congratulations on completing this comprehensive GARCH volatility modeling tutorial.\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "1. **Volatility Clustering**: Financial returns exhibit time-varying volatility with periods of high and low volatility that cluster together\n",
    "\n",
    "2. **ARCH Models**: Capture volatility clustering by modeling conditional variance as a function of past squared returns\n",
    "\n",
    "3. **GARCH Models**: Extend ARCH by including past conditional variances, creating persistence in volatility shocks\n",
    "\n",
    "4. **EGARCH Models**: Incorporate asymmetry (leverage effect) where negative shocks increase volatility more than positive shocks\n",
    "\n",
    "5. **Forecasting**: Generate multi-step ahead volatility forecasts that mean-revert to long-run levels\n",
    "\n",
    "6. **Position Sizing**: Scale trading positions inversely with forecasted volatility to maintain consistent risk\n",
    "\n",
    "7. **Technical Integration**: Combine GARCH with RSI and divergence analysis for robust trading signals\n",
    "\n",
    "8. **Complete System**: Build an end-to-end trading system with dynamic risk management\n",
    "\n",
    "### Critical Insights\n",
    "\n",
    "**For Traders:**\n",
    "- Use GARCH forecasts for position sizing, not just signal generation\n",
    "- Volatility regimes are as important as price direction\n",
    "- Risk management is dynamic, not static\n",
    "- Asymmetry matters: Protect downside more than upside\n",
    "\n",
    "**For Risk Managers:**\n",
    "- GARCH provides better VaR estimates than historical methods\n",
    "- Volatility persistence affects capital requirements\n",
    "- Model validation requires out-of-sample testing\n",
    "- Extreme events need separate tail risk models\n",
    "\n",
    "**For Researchers:**\n",
    "- Classical econometric models remain competitive with ML\n",
    "- Domain knowledge (asymmetry, clustering) beats black-box approaches\n",
    "- Parsimony wins: GARCH(1,1) often sufficient\n",
    "- Always validate assumptions (normality, stationarity)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Practice**: Work through the exercises to solidify understanding\n",
    "2. **Extend**: Try multivariate models (DCC-GARCH) for portfolio applications\n",
    "3. **Combine**: Integrate with machine learning for hybrid systems\n",
    "4. **Deploy**: Build a live trading system with proper infrastructure\n",
    "\n",
    "### Recommended Resources\n",
    "\n",
    "**Books:**\n",
    "- Ruey S. Tsay - \"Analysis of Financial Time Series\"\n",
    "- Carol Alexander - \"Market Risk Analysis, Volume II\"\n",
    "- John C. Hull - \"Options, Futures, and Other Derivatives\"\n",
    "\n",
    "**Papers:**\n",
    "- Bollerslev (1986) - Original GARCH paper\n",
    "- Nelson (1991) - EGARCH specification\n",
    "- Engle (2002) - Dynamic Conditional Correlation\n",
    "\n",
    "**Software:**\n",
    "- Python `arch` library: https://arch.readthedocs.io/\n",
    "- R `rugarch` package for advanced specifications\n",
    "- MATLAB Econometrics Toolbox\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "Volatility modeling is both an art and a science. The models provide structure, but practical application requires judgment, experience, and continuous learning. Markets evolve, and so must our models.\n",
    "\n",
    "The integration of classical econometrics (GARCH) with modern techniques (ML, deep learning) represents the frontier of quantitative finance. Master the fundamentals here, then explore the cutting edge.\n",
    "\n",
    "**Remember**: \"In theory, there is no difference between theory and practice. In practice, there is.\" - Yogi Berra\n",
    "\n",
    "Good luck in your quantitative trading journey!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
